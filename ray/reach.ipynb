{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c5de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-08-14 08:59:11</td></tr>\n",
       "<tr><td>Running for: </td><td>18:58:39.64        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.2/15.3 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 9.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    num_training_step_ca\n",
       "lls_per_iteration</th><th style=\"text-align: right;\">          num_env_steps_sample\n",
       "d_lifetime</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SAC_ReachEnvGym_d1f2c_00000</td><td>RUNNING </td><td>192.168.202.162:6776</td><td style=\"text-align: right;\">  1502</td><td style=\"text-align: right;\">         67633.7</td><td style=\"text-align: right;\">167</td><td style=\"text-align: right;\">1.505e+06</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 14:00:31,604\tWARNING algorithm_config.py:5033 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-08-13 14:00:31,605\tWARNING algorithm_config.py:5062 -- You configured a custom `model` config (probably through calling config.training(model=..), whereas your config uses the new API stack! In order to switch off the new API stack, set in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. If you DO want to use the new API stack, configure your model, instead, through: `config.rl_module(model_config={..})`.\n",
      "2025-08-13 14:00:31,606\tWARNING sac.py:487 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-08-13 14:00:31,606\tWARNING algorithm_config.py:5062 -- You configured a custom `model` config (probably through calling config.training(model=..), whereas your config uses the new API stack! In order to switch off the new API stack, set in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. If you DO want to use the new API stack, configure your model, instead, through: `config.rl_module(model_config={..})`.\n",
      "2025-08-13 14:00:31,607\tWARNING sac.py:487 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(pid=6776)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(pid=6776)\u001b[0m E0000 00:00:1755064832.440782    6776 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=6776)\u001b[0m E0000 00:00:1755064832.444170    6776 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=6776)\u001b[0m W0000 00:00:1755064832.453127    6776 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=6776)\u001b[0m W0000 00:00:1755064832.453145    6776 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=6776)\u001b[0m W0000 00:00:1755064832.453147    6776 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=6776)\u001b[0m W0000 00:00:1755064832.453148    6776 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:57)\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:58)\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/ey/rl/src/robosuite/robosuite/scripts/setup_macros.py (macros.py:59)\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not load the mink-based whole-body IK. Make sure you install related import properly, otherwise you will not be able to use the default IK controller setting for GR1 robot. (__init__.py:40)\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m \u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: ./common/reachController.json (composite_controller_factory.py:121)\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m \u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: ./common/reachController.json (composite_controller_factory.py:121)\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m 2025-08-13 14:00:36,391\tWARNING algorithm_config.py:5033 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m 2025-08-13 14:00:36,392\tWARNING algorithm_config.py:5062 -- You configured a custom `model` config (probably through calling config.training(model=..), whereas your config uses the new API stack! In order to switch off the new API stack, set in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. If you DO want to use the new API stack, configure your model, instead, through: `config.rl_module(model_config={..})`.\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m 2025-08-13 14:00:36,392\tWARNING sac.py:487 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m [2025-08-13 14:00:36,419 E 6776 6776] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: '1a131be32e3031e91aeda18401000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m [2025-08-13 14:00:36,437 E 6776 6776] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: '242586df03a2045518ccd63001000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m [2025-08-13 14:00:36,454 E 6776 6776] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: 'b8006f168c29d72081de145301000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m [2025-08-13 14:00:36,473 E 6776 6776] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: '54b65f3521b1cd55960d4fa301000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m [2025-08-13 14:00:36,494 E 6776 6776] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: 'fc3761cce604311dfeef14fa01000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m [2025-08-13 14:00:36,512 E 6776 6776] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: '7b728b5447d61d3be300180601000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(pid=6901)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 6x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(pid=6901)\u001b[0m E0000 00:00:1755064837.271749    6901 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=6901)\u001b[0m E0000 00:00:1755064837.275225    6901 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=6901)\u001b[0m W0000 00:00:1755064837.284029    6901 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6897)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:57)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6897)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:58)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6897)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/ey/rl/src/robosuite/robosuite/scripts/setup_macros.py (macros.py:59)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6899)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:57)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6899)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:58)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6899)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/ey/rl/src/robosuite/robosuite/scripts/setup_macros.py (macros.py:59)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not load the mink-based whole-body IK. Make sure you install related import properly, otherwise you will not be able to use the default IK controller setting for GR1 robot. (__init__.py:40)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m \u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: ./common/reachController.json (composite_controller_factory.py:121)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m \u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: ./common/reachController.json (composite_controller_factory.py:121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m [chatbus_1] 共享内存不存在，创建成功\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6895)\u001b[0m [chatbus_1] 共享内存已存在，连接成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m   gym.logger.warn(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m   gym.logger.warn(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m 2025-08-13 14:00:44,504\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m 2025-08-13 14:00:44,673\tWARNING algorithm_config.py:5062 -- You configured a custom `model` config (probably through calling config.training(model=..), whereas your config uses the new API stack! In order to switch off the new API stack, set in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. If you DO want to use the new API stack, configure your model, instead, through: `config.rl_module(model_config={..})`.\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m 2025-08-13 14:00:44,673\tWARNING sac.py:487 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m [2025-08-13 14:00:44,693 E 6776 6776] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: '0c4fd437f9ce492ad442d2b701000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(pid=7302)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(pid=7302)\u001b[0m E0000 00:00:1755064845.464260    7302 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=7302)\u001b[0m E0000 00:00:1755064845.467624    7302 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=7302)\u001b[0m W0000 00:00:1755064845.476245    7302 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:57)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:58)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/ey/rl/src/robosuite/robosuite/scripts/setup_macros.py (macros.py:59)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6901)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6901)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not load the mink-based whole-body IK. Make sure you install related import properly, otherwise you will not be able to use the default IK controller setting for GR1 robot. (__init__.py:40)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6901)\u001b[0m \u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: ./common/reachController.json (composite_controller_factory.py:121)\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6901)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6901)\u001b[0m   gym.logger.warn(\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6901)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m 2025-08-13 14:00:44,661\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m [chatbus_3] 共享内存不存在，创建成功\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6901)\u001b[0m [chatbus_1] 共享内存已存在，连接成功\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=7372)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(pid=7372)\u001b[0m E0000 00:00:1755064851.882582    7372 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=7372)\u001b[0m E0000 00:00:1755064851.886191    7372 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=7372)\u001b[0m W0000 00:00:1755064851.895047    7372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WrappedExecutable pid=7372)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:57)\n",
      "\u001b[36m(_WrappedExecutable pid=7372)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:58)\n",
      "\u001b[36m(_WrappedExecutable pid=7372)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/ey/rl/src/robosuite/robosuite/scripts/setup_macros.py (macros.py:59)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not load the mink-based whole-body IK. Make sure you install related import properly, otherwise you will not be able to use the default IK controller setting for GR1 robot. (__init__.py:40)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m \u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: ./common/reachController.json (composite_controller_factory.py:121)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m   gym.logger.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m 2025-08-13 14:00:51,141\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(_WrappedExecutable pid=7372)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\n",
      "\u001b[36m(_WrappedExecutable pid=7372)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not load the mink-based whole-body IK. Make sure you install related import properly, otherwise you will not be able to use the default IK controller setting for GR1 robot. (__init__.py:40)\n",
      "\u001b[36m(_WrappedExecutable pid=7372)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(_WrappedExecutable pid=7372)\u001b[0m 2025-08-13 14:01:11,628\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(_WrappedExecutable pid=7372)\u001b[0m \u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: ./common/reachController.json (composite_controller_factory.py:121)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m Trainable.setup took 36.334 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[36m(SAC pid=6776)\u001b[0m Install gputil for GPU system monitoring.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m   logger.warn(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m   logger.warn(f\"{pre} is not within the observation space.\")\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m   logger.warn(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=6891)\u001b[0m   logger.warn(f\"{pre} is not within the observation space.\")\n",
      "2025-08-13 14:05:13,500\tWARNING util.py:201 -- The `on_step_begin` operation took 0.506 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000000)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m   logger.warn(\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m   logger.warn(f\"{pre} is not within the observation space.\")\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=7302)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "2025-08-13 14:11:39,195\tWARNING util.py:201 -- The `callbacks.on_trial_result` operation took 0.830 s, which may be a performance bottleneck.\n",
      "2025-08-13 14:11:39,199\tWARNING util.py:201 -- The `process_trial_result` operation took 0.835 s, which may be a performance bottleneck.\n",
      "2025-08-13 14:11:39,200\tWARNING util.py:201 -- Processing trial results took 0.835 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2025-08-13 14:11:39,201\tWARNING util.py:201 -- The `process_trial_result` operation took 0.836 s, which may be a performance bottleneck.\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000001)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000002)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000003)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000004)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000005)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000006)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000007)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000008)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000009)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000010)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000011)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000012)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000013)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000014)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000015)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000016)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000017)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000018)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000019)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000020)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000021)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000022)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000023)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000024)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000025)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000026)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000027)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000028)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000029)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000030)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000031)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000032)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000033)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000034)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000035)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000036)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000037)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000038)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000039)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000040)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000041)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000042)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000043)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000044)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000045)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000046)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000047)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000048)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000049)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000050)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000051)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000052)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000053)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000054)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000055)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000056)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000057)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000058)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000059)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000060)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000061)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000062)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000063)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000064)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000065)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000066)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000067)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000068)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000069)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000070)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000071)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000072)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000073)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000074)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000075)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000076)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000077)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000078)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000079)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000080)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000081)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000082)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000083)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000084)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000085)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000086)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000087)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000088)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000089)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000090)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000091)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000092)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000093)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000094)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000095)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000096)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000097)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000098)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000099)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000100)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000101)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000102)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000103)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000104)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000105)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000106)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000107)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000108)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000109)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000110)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000111)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000112)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000113)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000114)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000115)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000116)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000117)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000118)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000119)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000120)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000121)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000122)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000123)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000124)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000125)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000126)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000127)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000128)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000129)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000130)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000131)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000132)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000133)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000134)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000135)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000136)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000137)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000138)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000139)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000140)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000141)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000142)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000143)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000144)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000145)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000146)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000147)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000148)\n",
      "\u001b[36m(SAC(env=<class 'common.envUtils.ReachEnvGym'>; env-runners=6; learners=1; multi-agent=False) pid=6776)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-13_14-00-29/reach/SAC_ReachEnvGym_d1f2c_00000_0_2025-08-13_14-00-31/checkpoint_000149)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from ray import train, tune, air\n",
    "from ray.rllib.algorithms.sac import SACConfig\n",
    "from common.envUtils import *\n",
    "\n",
    "TASK=\"Reach_\"\n",
    "experiment_name = TASK + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "LOGDIR=f\"/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/{experiment_name}\"\n",
    "\n",
    "config = (\n",
    "    SACConfig()\n",
    "    .environment(\n",
    "        env=ReachEnvGym,\n",
    "        env_config={\"log_dir\": LOGDIR},        \n",
    "    )\n",
    "    .training(\n",
    "        initial_alpha=0.2,\n",
    "        actor_lr=1e-4,\n",
    "        critic_lr=1e-4,\n",
    "        alpha_lr=1e-4,\n",
    "        target_entropy=\"auto\",\n",
    "        n_step=1,\n",
    "        tau=0.005,\n",
    "        train_batch_size=128,\n",
    "        target_network_update_freq=1,\n",
    "        replay_buffer_config={\n",
    "            \"type\": \"EpisodeReplayBuffer\",\n",
    "            \"capacity\": 1000000,\n",
    "            \"learning_starts\": 1000,\n",
    "            # HER 专用参数\n",
    "            \"replay_mode\": \"independent\",\n",
    "            \"replay_sequence_length\": 1,\n",
    "            \"replay_burn_in\": 0,\n",
    "            \"replay_zero_init_states\": False,\n",
    "            \"storage_unit\": \"episodes\",\n",
    "            # 关键：HER wrapper 配置\n",
    "            \"wrap_buffer\": True,\n",
    "            \"wrapped_buffer\": {\n",
    "                \"type\": \"HindsightExperienceReplayBuffer\",\n",
    "                \"replay_mode\": \"independent\",\n",
    "                \"her_strategy\": \"future\",      # 可选: future, final, episode\n",
    "                \"replay_k\": 4,                 # 每个 transition 生成多少个 HER 样本\n",
    "                \"goal_fn\": None,               # 你可以自定义 goal extraction function\n",
    "            },\n",
    "        },\n",
    "        num_steps_sampled_before_learning_starts=1000,\n",
    "        model={\n",
    "            \"fcnet_hiddens\": [512, 512],\n",
    "            \"fcnet_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [],\n",
    "            \"post_fcnet_activation\": None,\n",
    "            \"post_fcnet_weights_initializer\": \"orthogonal_\",\n",
    "            \"post_fcnet_weights_initializer_config\": {\"gain\": 0.01},\n",
    "        },\n",
    "    )\n",
    "    .resources(\n",
    "        num_gpus=0.25,      # 或 0.25 视机器配置\n",
    "        num_cpus_per_worker=1,\n",
    "        num_learner_workers=1,\n",
    "    )\n",
    "    .framework(\"torch\")\n",
    "    .reporting(\n",
    "        metrics_num_episodes_for_smoothing=5,\n",
    "        min_sample_timesteps_per_iteration=1000,\n",
    "    )\n",
    "    .evaluation(\n",
    "        evaluation_interval=1,\n",
    "        evaluation_num_env_runners=1,\n",
    "        evaluation_config={\"seed\": 42},\n",
    "    )\n",
    "    .env_runners(\n",
    "        num_env_runners=5,             # 进程数量\n",
    "        num_envs_per_env_runner=1,     # 环境数量\n",
    "        # gym_env_vectorize_mode=\"ASYNC\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "tunner = tune.Tuner(\n",
    "    trainable=config.algo_class,\n",
    "    param_space=config,\n",
    "    run_config=train.RunConfig(\n",
    "        name=\"reach\",\n",
    "        storage_path=LOGDIR,\n",
    "        log_to_file=True,\n",
    "        checkpoint_config=air.CheckpointConfig(\n",
    "            checkpoint_frequency=10,\n",
    "            checkpoint_at_end=True,\n",
    "        ),\n",
    "        stop={\"evaluation/env_runners/episode_return_mean\": 12000.0}\n",
    "    ),\n",
    ")\n",
    "\n",
    "results = tunner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import gymnasium as gym\n",
    "import numpy as np \n",
    "import torch\n",
    "from ray.rllib.core.rl_module import RLModule\n",
    "from ray.rllib.algorithms.sac import SACConfig\n",
    "from ray.rllib.models.torch.torch_distributions import TorchDiagGaussian\n",
    "from common.envUtils import *\n",
    "\n",
    "TASK=\"Reach_\"\n",
    "experiment_name = TASK + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "LOGDIR=f\"/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/{experiment_name}\"\n",
    "\n",
    "checkpoint_path = \"/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/Reach_2025-08-09_16-32-52/reach/SAC_ReachEnvGym_714b7_00000_0_2025-08-09_16-32-53/checkpoint_000283\"\n",
    "rl_module = RLModule.from_checkpoint(\n",
    "    Path(checkpoint_path)\n",
    "    / \"learner_group\"\n",
    "    / \"learner\"\n",
    "    / \"rl_module\"\n",
    "    / \"default_policy\"\n",
    ")\n",
    "\n",
    "env = make_reach_env()\n",
    "obs, info = env.reset()\n",
    "\n",
    "# print(obs.dtype)\n",
    "obs_batch = torch.from_numpy(obs.astype(np.float32)).unsqueeze(0)\n",
    "model_outputs = rl_module.forward_inference({\"obs\": obs_batch})\n",
    "print(model_outputs)\n",
    "logits = model_outputs[\"action_dist_inputs\"]\n",
    "dist_class = rl_module.get_inference_action_dist_cls()\n",
    "dist = dist_class.from_logits(logits)\n",
    "action_sample = dist.sample()\n",
    "action = action_sample.squeeze(0).detach().numpy().astype(np.float32)\n",
    "print(action_sample)\n",
    "print(action)\n",
    "obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "print(f\"obs:{obs}\")\n",
    "print(f\"reward:{reward}\")\n",
    "print(f\"terminated:{terminated}\")\n",
    "print(f\"truncated:{truncated}\")\n",
    "print(f\"info:{info}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28bd8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-08-13 09:48:54</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:45.48        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.2/15.3 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SAC_ReachEnvSimpleGym_90614_00000</td><td>RUNNING </td><td>192.168.202.162:310693</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 09:48:09,215\tWARNING algorithm_config.py:5033 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-08-13 09:48:09,217\tWARNING algorithm_config.py:5062 -- You configured a custom `model` config (probably through calling config.training(model=..), whereas your config uses the new API stack! In order to switch off the new API stack, set in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. If you DO want to use the new API stack, configure your model, instead, through: `config.rl_module(model_config={..})`.\n",
      "2025-08-13 09:48:09,217\tWARNING sac.py:487 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-08-13 09:48:09,218\tWARNING algorithm_config.py:5062 -- You configured a custom `model` config (probably through calling config.training(model=..), whereas your config uses the new API stack! In order to switch off the new API stack, set in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. If you DO want to use the new API stack, configure your model, instead, through: `config.rl_module(model_config={..})`.\n",
      "2025-08-13 09:48:09,219\tWARNING sac.py:487 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(pid=310693)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(pid=310693)\u001b[0m E0000 00:00:1755049690.077845  310693 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=310693)\u001b[0m E0000 00:00:1755049690.081397  310693 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=310693)\u001b[0m W0000 00:00:1755049690.091002  310693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=310693)\u001b[0m W0000 00:00:1755049690.091028  310693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=310693)\u001b[0m W0000 00:00:1755049690.091030  310693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=310693)\u001b[0m W0000 00:00:1755049690.091032  310693 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:57)\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:58)\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/ey/rl/src/robosuite/robosuite/scripts/setup_macros.py (macros.py:59)\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not load the mink-based whole-body IK. Make sure you install related import properly, otherwise you will not be able to use the default IK controller setting for GR1 robot. (__init__.py:40)\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m \u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: ./common/reachController.json (composite_controller_factory.py:121)\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m \u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: ./common/reachController.json (composite_controller_factory.py:121)\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m 2025-08-13 09:48:14,084\tWARNING algorithm_config.py:5033 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m 2025-08-13 09:48:14,084\tWARNING algorithm_config.py:5062 -- You configured a custom `model` config (probably through calling config.training(model=..), whereas your config uses the new API stack! In order to switch off the new API stack, set in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. If you DO want to use the new API stack, configure your model, instead, through: `config.rl_module(model_config={..})`.\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m 2025-08-13 09:48:14,085\tWARNING sac.py:487 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m [2025-08-13 09:48:14,120 E 310693 310693] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: 'cdca7947e373f42905c05d3701000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m [2025-08-13 09:48:14,140 E 310693 310693] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: '72fbb8310044ec002134097b01000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m [2025-08-13 09:48:14,160 E 310693 310693] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: 'fcc8058e1c74b02cf86a31d301000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m [2025-08-13 09:48:14,179 E 310693 310693] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: '6251ab3e8e9da41fb9f4973201000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m [2025-08-13 09:48:14,198 E 310693 310693] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: '3e87440d6ca12be47d6635a101000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(pid=310811)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(pid=310811)\u001b[0m E0000 00:00:1755049694.949474  310811 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=310811)\u001b[0m E0000 00:00:1755049694.953121  310811 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=310810)\u001b[0m W0000 00:00:1755049694.956800  310810 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:57)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:58)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/ey/rl/src/robosuite/robosuite/scripts/setup_macros.py (macros.py:59)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310811)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:57)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310811)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:58)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310811)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/ey/rl/src/robosuite/robosuite/scripts/setup_macros.py (macros.py:59)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not load the mink-based whole-body IK. Make sure you install related import properly, otherwise you will not be able to use the default IK controller setting for GR1 robot. (__init__.py:40)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m \u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: ./common/reachController.json (composite_controller_factory.py:121)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310811)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310811)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not load the mink-based whole-body IK. Make sure you install related import properly, otherwise you will not be able to use the default IK controller setting for GR1 robot. (__init__.py:40)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m [chatbus_3] 共享内存不存在，创建成功\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310811)\u001b[0m [chatbus_3] 共享内存已存在，连接成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=310810, ip=192.168.202.162, actor_id=6251ab3e8e9da41fb9f4973201000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x7dec5e7242e0>)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/multiprocessing/shared_memory.py\", line 104, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     self._fd = _posixshmem.shm_open(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m FileNotFoundError: [Errno 2] No such file or directory: '/chatbus_3'\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m \n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m \n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=310810, ip=192.168.202.162, actor_id=6251ab3e8e9da41fb9f4973201000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x7dec5e7242e0>)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/ray/rllib/env/single_agent_env_runner.py\", line 104, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     self.make_env()\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/ray/rllib/env/single_agent_env_runner.py\", line 675, in make_env\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     gym.make_vec(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 918, in make_vec\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     env = gym.vector.SyncVectorEnv(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/vector/sync_vector_env.py\", line 86, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     self.envs = [env_fn() for env_fn in env_fns]\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/vector/sync_vector_env.py\", line 86, in <listcomp>\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     self.envs = [env_fn() for env_fn in env_fns]\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 903, in create_single_env\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     single_env = make(env_spec, **env_spec_kwargs.copy())\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 740, in make\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     env = env_creator(**env_spec_kwargs)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/ray/rllib/env/utils/__init__.py\", line 118, in _gym_env_creator\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     env = env_descriptor(env_context)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/rl/src/rlreach2/rlreach/ray/common/envUtils.py\", line 188, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     self.env = make_reach_simple_env(log_dir=env_config.get(\"log_dir\"))\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/rl/src/rlreach2/rlreach/ray/common/envUtils.py\", line 182, in make_reach_simple_env\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     env = ReachEnv(**eval_env_config, log_dir=log_dir)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/rl/src/rlreach2/rlreach/ray/common/reachEnv.py\", line 102, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     self.channel = SharedMemoryChannel(f\"chatbus_{n_env}\")   #\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/rl/src/rlreach2/rlreach/ray/common/shmUtils.py\", line 17, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     self.shm = shared_memory.SharedMemory(name=name, create=True, size=size)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/multiprocessing/shared_memory.py\", line 104, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m     self._fd = _posixshmem.shm_open(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310810)\u001b[0m FileExistsError: [Errno 17] File exists: '/chatbus_3'\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m   gym.logger.warn(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m   gym.logger.warn(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m 2025-08-13 09:48:20,904\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m 2025-08-13 09:48:20,925\tERROR actor_manager.py:873 -- Ray error (The actor died because of an error raised in its creation task, \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=310810, ip=192.168.202.162, actor_id=6251ab3e8e9da41fb9f4973201000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x7dec5e7242e0>)\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m \n",
      "\u001b[36m(SAC pid=310693)\u001b[0m \n",
      "\u001b[36m(SAC pid=310693)\u001b[0m FileExistsError: [Errno 17] File exists: '/chatbus_3'), taking actor 4 out of service.\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m 2025-08-13 09:48:20,925\tERROR env_runner_group.py:758 -- Validation of EnvRunner failed! Error=The actor died because of an error raised in its creation task, \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=310810, ip=192.168.202.162, actor_id=6251ab3e8e9da41fb9f4973201000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x7dec5e7242e0>)\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m \n",
      "\u001b[36m(SAC pid=310693)\u001b[0m \n",
      "\u001b[36m(SAC pid=310693)\u001b[0m 2025-08-13 09:48:21,033\tWARNING algorithm_config.py:5062 -- You configured a custom `model` config (probably through calling config.training(model=..), whereas your config uses the new API stack! In order to switch off the new API stack, set in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. If you DO want to use the new API stack, configure your model, instead, through: `config.rl_module(model_config={..})`.\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m 2025-08-13 09:48:21,033\tWARNING sac.py:487 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m [2025-08-13 09:48:21,055 E 310693 310693] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: '1a9c10693898678df0c8556c01000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(pid=311140)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(pid=311140)\u001b[0m E0000 00:00:1755049701.921583  311140 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=311140)\u001b[0m E0000 00:00:1755049701.925092  311140 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=311140)\u001b[0m W0000 00:00:1755049701.934848  311140 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:57)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:58)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/ey/rl/src/robosuite/robosuite/scripts/setup_macros.py (macros.py:59)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310807)\u001b[0m \u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: ./common/reachController.json (composite_controller_factory.py:121)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310807)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310807)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not load the mink-based whole-body IK. Make sure you install related import properly, otherwise you will not be able to use the default IK controller setting for GR1 robot. (__init__.py:40)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/multiprocessing/shared_memory.py\", line 104, in __init__\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m     self._fd = _posixshmem.shm_open(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m FileNotFoundError: [Errno 2] No such file or directory: '/chatbus_3'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m During handling of the above exception, another exception occurred:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=310810, ip=192.168.202.162, actor_id=6251ab3e8e9da41fb9f4973201000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x7dec5e7242e0>)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m     self.make_env()\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/ray/rllib/env/single_agent_env_runner.py\", line 675, in make_env\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m     gym.make_vec(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 918, in make_vec\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m     env = gym.vector.SyncVectorEnv(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m     self.envs = [env_fn() for env_fn in env_fns]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/vector/sync_vector_env.py\", line 86, in <listcomp>\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 903, in create_single_env\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m     single_env = make(env_spec, **env_spec_kwargs.copy())\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/envs/registration.py\", line 740, in make\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m     env = env_creator(**env_spec_kwargs)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m   File \"/home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/ray/rllib/env/utils/__init__.py\", line 118, in _gym_env_creator\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m     env = env_descriptor(env_context)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m     self.env = make_reach_simple_env(log_dir=env_config.get(\"log_dir\"))\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m   File \"/home/ey/rl/src/rlreach2/rlreach/ray/common/envUtils.py\", line 182, in make_reach_simple_env\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m     env = ReachEnv(**eval_env_config, log_dir=log_dir)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m     self.channel = SharedMemoryChannel(f\"chatbus_{n_env}\")   #\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m     self.shm = shared_memory.SharedMemory(name=name, create=True, size=size)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m FileExistsError: [Errno 17] File exists: '/chatbus_3'\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310807)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310807)\u001b[0m   gym.logger.warn(\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310807)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m 2025-08-13 09:48:21,021\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m [chatbus_5] 共享内存不存在，创建成功\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310809)\u001b[0m [chatbus_3] 共享内存已存在，连接成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=311210)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(pid=311210)\u001b[0m E0000 00:00:1755049708.914570  311210 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=311210)\u001b[0m E0000 00:00:1755049708.918280  311210 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=311210)\u001b[0m W0000 00:00:1755049708.927947  311210 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_WrappedExecutable pid=311210)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:57)\n",
      "\u001b[36m(_WrappedExecutable pid=311210)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:58)\n",
      "\u001b[36m(_WrappedExecutable pid=311210)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/ey/rl/src/robosuite/robosuite/scripts/setup_macros.py (macros.py:59)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m \u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: ./common/reachController.json (composite_controller_factory.py:121)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not load the mink-based whole-body IK. Make sure you install related import properly, otherwise you will not be able to use the default IK controller setting for GR1 robot. (__init__.py:40)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m   gym.logger.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m 2025-08-13 09:48:28,158\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(_WrappedExecutable pid=311210)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\n",
      "\u001b[36m(_WrappedExecutable pid=311210)\u001b[0m \u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not load the mink-based whole-body IK. Make sure you install related import properly, otherwise you will not be able to use the default IK controller setting for GR1 robot. (__init__.py:40)\n",
      "\u001b[36m(_WrappedExecutable pid=311210)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(_WrappedExecutable pid=311210)\u001b[0m 2025-08-13 09:48:47,457\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(_WrappedExecutable pid=311210)\u001b[0m \u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: ./common/reachController.json (composite_controller_factory.py:121)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m Trainable.setup took 34.430 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[36m(SAC pid=310693)\u001b[0m Install gputil for GPU system monitoring.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m   logger.warn(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m   logger.warn(f\"{pre} is not within the observation space.\")\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m   logger.warn(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=310808)\u001b[0m   logger.warn(f\"{pre} is not within the observation space.\")\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m   logger.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m   logger.warn(f\"{pre} is not within the observation space.\")\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=311140)\u001b[0m /home/ey/anaconda3/envs/rlreach310/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from ray import train, tune, air\n",
    "from ray.rllib.algorithms.sac import SACConfig\n",
    "from common.envUtils import *\n",
    "\n",
    "TASK=\"Reach_\"\n",
    "experiment_name = TASK + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "LOGDIR=f\"/home/ey/rl/src/rlreach2/rlreach/ray/db/ray_results/{experiment_name}\"\n",
    "\n",
    "config = (\n",
    "    SACConfig()\n",
    "    .environment(\n",
    "        env=ReachEnvSimpleGym,\n",
    "        env_config={\"log_dir\": LOGDIR},        \n",
    "    )\n",
    "    .training(\n",
    "        initial_alpha=0.2,\n",
    "        actor_lr=1e-4,\n",
    "        critic_lr=1e-4,\n",
    "        alpha_lr=1e-4,\n",
    "        target_entropy=\"auto\",\n",
    "        n_step=1,\n",
    "        tau=0.005,\n",
    "        train_batch_size=128,\n",
    "        target_network_update_freq=1,\n",
    "        replay_buffer_config={\n",
    "            \"type\": \"EpisodeReplayBuffer\",\n",
    "            \"capacity\": 1000000,\n",
    "            \"learning_starts\": 1000,\n",
    "            # HER 专用参数\n",
    "            \"replay_mode\": \"independent\",\n",
    "            \"replay_sequence_length\": 1,\n",
    "            \"replay_burn_in\": 0,\n",
    "            \"replay_zero_init_states\": False,\n",
    "            \"storage_unit\": \"episodes\",\n",
    "            # 关键：HER wrapper 配置\n",
    "            \"wrap_buffer\": True,\n",
    "            \"wrapped_buffer\": {\n",
    "                \"type\": \"HindsightExperienceReplayBuffer\",\n",
    "                \"replay_mode\": \"independent\",\n",
    "                \"her_strategy\": \"future\",      # 可选: future, final, episode\n",
    "                \"replay_k\": 4,                 # 每个 transition 生成多少个 HER 样本\n",
    "                \"goal_fn\": None,               # 你可以自定义 goal extraction function\n",
    "            },\n",
    "        },\n",
    "        num_steps_sampled_before_learning_starts=1000,\n",
    "        model={\n",
    "            \"fcnet_hiddens\": [512, 512],\n",
    "            \"fcnet_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [],\n",
    "            \"post_fcnet_activation\": None,\n",
    "            \"post_fcnet_weights_initializer\": \"orthogonal_\",\n",
    "            \"post_fcnet_weights_initializer_config\": {\"gain\": 0.01},\n",
    "        },\n",
    "    )\n",
    "    .resources(\n",
    "        num_gpus=0.25,      # 或 0.25 视机器配置\n",
    "        num_cpus_per_worker=1,\n",
    "        num_learner_workers=1,\n",
    "    )\n",
    "    .framework(\"torch\")\n",
    "    .reporting(\n",
    "        metrics_num_episodes_for_smoothing=5,\n",
    "        min_sample_timesteps_per_iteration=1000,\n",
    "    )\n",
    "    .evaluation(\n",
    "        evaluation_interval=1,\n",
    "        evaluation_num_env_runners=1,\n",
    "        evaluation_config={\"seed\": 42},\n",
    "    )\n",
    "    .env_runners(\n",
    "        num_env_runners=6,             # 进程数量\n",
    "        num_envs_per_env_runner=1,     # 环境数量\n",
    "        # gym_env_vectorize_mode=\"ASYNC\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "tunner = tune.Tuner(\n",
    "    trainable=config.algo_class,\n",
    "    param_space=config,\n",
    "    run_config=train.RunConfig(\n",
    "        name=\"reach\",\n",
    "        storage_path=LOGDIR,\n",
    "        log_to_file=True,\n",
    "        checkpoint_config=air.CheckpointConfig(\n",
    "            checkpoint_frequency=10,\n",
    "            checkpoint_at_end=True,\n",
    "        ),\n",
    "        stop={\"evaluation/env_runners/episode_return_mean\": 10000.0}\n",
    "    ),\n",
    ")\n",
    "\n",
    "results = tunner.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlreach310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
